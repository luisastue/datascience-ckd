{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK_OZhX_7VK2"
      },
      "source": [
        "Laura, Luisa, Ahmed, Kia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIZ5OO-dquZH",
        "outputId": "3c0eabcd-9bd0-43c4-d3a9-1d4ddd97c96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.9/dist-packages (4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.9/dist-packages (2.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install rarfile\n",
        "!pip install scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXJthmjt62qv",
        "outputId": "7cda5ee2-adc9-4b45-b6f9-e049ef5adfde"
      },
      "outputs": [
        {
          "ename": "BadRarFile",
          "evalue": "Failed the read enough data: req=44268 got=51",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRarFile\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Extract the ARFF file from the RAR file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mwith\u001b[39;00m rarfile\u001b[39m.\u001b[39mRarFile(io\u001b[39m.\u001b[39mBytesIO(rar_file)) \u001b[39mas\u001b[39;00m rf:\n\u001b[0;32m---> 19\u001b[0m     arff_file \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39;49mread(\u001b[39m\"\u001b[39;49m\u001b[39mChronic_Kidney_Disease/chronic_kidney_disease.arff\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Decode the ARFF file bytes into a string\u001b[39;00m\n\u001b[1;32m     22\u001b[0m arff_file_decoded \u001b[39m=\u001b[39m arff_file\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/rarfile.py:799\u001b[0m, in \u001b[0;36mRarFile.read\u001b[0;34m(self, name, pwd)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return uncompressed data for archive entry.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \n\u001b[1;32m    788\u001b[0m \u001b[39mFor longer files using :meth:`~RarFile.open` may be better idea.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39m        password to use for extracting.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(name, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, pwd) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 799\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mread()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/rarfile.py:2197\u001b[0m, in \u001b[0;36mRarExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   2195\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(buf)\n\u001b[1;32m   2196\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2197\u001b[0m     \u001b[39mraise\u001b[39;00m BadRarFile(\u001b[39m\"\u001b[39m\u001b[39mFailed the read enough data: req=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m got=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (orig, \u001b[39mlen\u001b[39m(data)))\n\u001b[1;32m   2199\u001b[0m \u001b[39m# done?\u001b[39;00m\n\u001b[1;32m   2200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remain \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2201\u001b[0m     \u001b[39m# self.close()\u001b[39;00m\n",
            "\u001b[0;31mBadRarFile\u001b[0m: Failed the read enough data: req=44268 got=51"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "import rarfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Download the RAR file\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00336/Chronic_Kidney_Disease.rar\"\n",
        "rar_file = requests.get(url).content\n",
        "\n",
        "# Extract the ARFF file from the RAR file\n",
        "with rarfile.RarFile(io.BytesIO(rar_file)) as rf:\n",
        "    arff_file = rf.read(\"Chronic_Kidney_Disease/chronic_kidney_disease.arff\")\n",
        "\n",
        "# Decode the ARFF file bytes into a string\n",
        "arff_file_decoded = arff_file.decode('utf-8')\n",
        "\n",
        "# Replace 'yes' and 'no' with 'true' and 'false'\n",
        "arff_file_decoded = arff_file_decoded.replace('yes', 'true')\n",
        "arff_file_decoded = arff_file_decoded.replace('no', 'false')\n",
        "\n",
        "# Remove the attribute lines before the @data tag\n",
        "arff_file_decoded = arff_file_decoded.split('@data', 1)[1]\n",
        "\n",
        "# Remove any lines with more than 24 columns\n",
        "arff_data = [line.strip().split(',') for line in arff_file_decoded.split('\\n') if line.strip() and len(line.strip().split(',')) <= 25]\n",
        "\n",
        "# Load the modified ARFF file into a pandas DataFrame\n",
        "df = pd.DataFrame(arff_data)\n",
        "\n",
        "# Assign column names to the DataFrame\n",
        "df.columns = ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']\n",
        "\n",
        "# Replace '?' with NaN\n",
        "df = df.replace('?', pd.np.nan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "iDchbUSfCJb5",
        "outputId": "a6e65a59-04f0-4eb8-9fd2-d140671c0a97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-546d62c9-6411-4c0b-b721-3012f63ab72c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-546d62c9-6411-4c0b-b721-3012f63ab72c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kidney_disease-1.csv to kidney_disease-1.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploades = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMdLdiQuCYfa",
        "outputId": "ed130e2e-cb72-4ad2-8cfb-4c6f1f798cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               id         age          bp          sg          al          su  \\\n",
            "count  158.000000  158.000000  158.000000  158.000000  158.000000  158.000000   \n",
            "mean   274.841772   49.563291   74.050633    1.019873    0.797468    0.253165   \n",
            "std    102.998517   15.512244   11.175381    0.005499    1.413130    0.813397   \n",
            "min      3.000000    6.000000   50.000000    1.005000    0.000000    0.000000   \n",
            "25%    243.000000   39.250000   60.000000    1.020000    0.000000    0.000000   \n",
            "50%    298.500000   50.500000   80.000000    1.020000    0.000000    0.000000   \n",
            "75%    355.750000   60.000000   80.000000    1.025000    1.000000    0.000000   \n",
            "max    399.000000   83.000000  110.000000    1.025000    4.000000    5.000000   \n",
            "\n",
            "              bgr          bu          sc         sod         pot        hemo  \n",
            "count  158.000000  158.000000  158.000000  158.000000  158.000000  158.000000  \n",
            "mean   131.341772   52.575949    2.188608  138.848101    4.636709   13.687342  \n",
            "std     64.939832   47.395382    3.077615    7.489421    3.476351    2.882204  \n",
            "min     70.000000   10.000000    0.400000  111.000000    2.500000    3.100000  \n",
            "25%     97.000000   26.000000    0.700000  135.000000    3.700000   12.600000  \n",
            "50%    115.500000   39.500000    1.100000  139.000000    4.500000   14.250000  \n",
            "75%    131.750000   49.750000    1.600000  144.000000    4.900000   15.775000  \n",
            "max    490.000000  309.000000   15.200000  150.000000   47.000000   17.800000  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"kidney_disease-1.csv\")\n",
        "\n",
        "# Drop all rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Get a summary of the numerical columns in the dataframe\n",
        "summary = df.describe()\n",
        "\n",
        "# Get a summary of the categorical columns in the dataframe\n",
        "cat_summary = df.describe(include=['O'])\n",
        "\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya5ReL9IDJci",
        "outputId": "55bac75c-95fa-4dd7-805f-2ec2249e8fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           rbc      pc         pcc          ba  pcv    wc   rc  htn   dm  cad  \\\n",
            "count      158     158         158         158  158   158  158  158  158  158   \n",
            "unique       2       2           2           2   34    71   41    2    2    2   \n",
            "top     normal  normal  notpresent  notpresent   52  6700  4.5   no   no   no   \n",
            "freq       140     129         144         146   15     7   12  124  130  147   \n",
            "\n",
            "       appet   pe  ane classification  \n",
            "count    158  158  158            158  \n",
            "unique     2    2    2              2  \n",
            "top     good   no   no         notckd  \n",
            "freq     139  138  142            115  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(cat_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "sCXz3kSwAk1C",
        "outputId": "fee6a674-f021-41d2-de44-55586dfb70e2"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-34bde7ce4029>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Convert the data to PyTorch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"kidney_disease-1.csv\")\n",
        "\n",
        "# Drop all rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Encode categorical variables using one-hot encoding\n",
        "cat_cols = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
        "transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), cat_cols)], remainder='passthrough')\n",
        "df = transformer.fit_transform(df)\n",
        "\n",
        "# Separate the features and target variable\n",
        "X = df[:, :-1]\n",
        "y = df[:, -1]\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the numerical features\n",
        "num_cols = [1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 15]\n",
        "scaler = StandardScaler()\n",
        "X_train[:, num_cols] = scaler.fit_transform(X_train[:, num_cols])\n",
        "X_test[:, num_cols] = scaler.transform(X_test[:, num_cols])\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Define the neural network model\n",
        "class KidneyDiseaseClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(32, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model = KidneyDiseaseClassifier()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test)\n",
        "    y_pred_class = y_pred.round()\n",
        "    accuracy = (y_pred_class == y_test).sum() / y_test.shape[0]\n",
        "    print(f\"Accuracy: {accuracy.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9tH5EnZA5ey"
      },
      "outputs": [],
      "source": [
        "# Convert the data to numpy arrays\n",
        "X = df.drop('class', axis=1).values\n",
        "y = df['class'].values\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "F5ur8ErB8gZP",
        "outputId": "b7aef5e3-225f-4409-a4eb-f9b7a96fd960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-0e652e1f68db>:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  median = X_train.median()\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0e652e1f68db>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Convert the data to PyTorch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '?'"
          ]
        }
      ],
      "source": [
        "# Impute missing values with median\n",
        "median = X_train.median()\n",
        "X_train = X_train.fillna(median)\n",
        "X_test = X_test.fillna(median)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train.values.astype(float))\n",
        "X_test = torch.tensor(X_test.values.astype(float))\n",
        "y_train = torch.tensor(y_train.values.astype(float))\n",
        "y_test = torch.tensor(y_test.values.astype(float))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "_IHOs_2u8WNI",
        "outputId": "b0ba358a-40b3-48a4-bd21-8dbba5ace73b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-3c529c37b410>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Convert the data to PyTorch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '?'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "# ...\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis=1), df['class'], test_size=0.2)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train.values.astype(float))\n",
        "X_test = torch.tensor(X_test.values.astype(float))\n",
        "y_train = torch.tensor(y_train.values.astype(float))\n",
        "y_test = torch.tensor(y_test.values.astype(float))\n",
        "\n",
        "# Define the neural network architecture\n",
        "class CKDNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(24, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the neural network\n",
        "net = CKDNet()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# Train the neural network\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(X_train.float())\n",
        "    loss = criterion(outputs, y_train.view(-1, 1).float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch} Loss: {loss.item()}\")\n",
        "\n",
        "# Evaluate the neural network on the test set\n",
        "with torch.no_grad():\n",
        "    outputs = net(X_test.float())\n",
        "    predicted = torch.round(outputs)\n",
        "    accuracy = (predicted == y_test.view(-1, 1)).sum().item() / len(y_test)\n",
        "    print(f\"Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Q_tgh58Ytq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
